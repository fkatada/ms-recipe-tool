# This file was generated by Codebase-Generator, do not edit directly
"""
ParallelStep allows concurrent execution of multiple sub-steps (execute_recipe steps) with isolation.
"""

import asyncio
import logging
from typing import Any, Dict, List, Optional, Awaitable, Set

from recipe_executor.steps.base import BaseStep, StepConfig
from recipe_executor.steps.registry import STEP_REGISTRY
from recipe_executor.protocols import ContextProtocol, StepProtocol


class ParallelConfig(StepConfig):
    """Config for ParallelStep.

    Fields:
        substeps: List of sub-step definitions, each a dict with 'type' and 'config'.
        max_concurrency: Maximum number of substeps to run concurrently. 0 means unlimited.
        delay: Optional delay (in seconds) between launching each substep.
        timeout: Optional timeout (in seconds) for the entire parallel execution.
    """

    substeps: List[Dict[str, Any]]
    max_concurrency: int = 0
    delay: float = 0.0
    timeout: Optional[float] = None


class ParallelStep(BaseStep[ParallelConfig]):
    """Step to execute multiple sub-steps in parallel."""

    def __init__(self, logger: logging.Logger, config: Dict[str, Any]) -> None:
        validated: ParallelConfig = ParallelConfig.model_validate(config)
        super().__init__(logger, validated)

    async def execute(self, context: ContextProtocol) -> None:
        substeps: List[Dict[str, Any]] = self.config.substeps or []
        total_steps: int = len(substeps)
        max_concurrency: int = self.config.max_concurrency
        delay_between: float = self.config.delay
        timeout_seconds: Optional[float] = self.config.timeout

        self.logger.debug("ParallelStep configuration: %s", self.config)
        self.logger.info(
            "Starting ParallelStep: %d substeps, max_concurrency=%d, delay=%.3f, timeout=%s",
            total_steps,
            max_concurrency,
            delay_between,
            f"{timeout_seconds}s" if timeout_seconds is not None else "none",
        )

        if total_steps == 0:
            self.logger.info("No substeps to execute; skipping ParallelStep.")
            return

        # Determine concurrency limit: 0 or negative => unlimited
        concurrency_limit: int = total_steps if max_concurrency <= 0 else min(max_concurrency, total_steps)
        semaphore: asyncio.Semaphore = asyncio.Semaphore(concurrency_limit)

        # Track failure
        failure_exception: Optional[Exception] = None
        failure_index: Optional[int] = None
        tasks: List[asyncio.Task] = []

        async def run_substep(index: int, spec: Dict[str, Any]) -> None:
            nonlocal failure_exception, failure_index
            sub_logger: logging.Logger = self.logger.getChild(f"substep_{index}")
            try:
                sub_logger.debug(
                    "Preparing substep %d: cloning context; spec=%s",
                    index,
                    spec,
                )
                sub_context: ContextProtocol = context.clone()

                step_type: Optional[str] = spec.get("type")
                if not step_type or step_type not in STEP_REGISTRY:
                    raise RuntimeError(f"Unknown step type '{step_type}' for substep {index}")

                step_config_dict: Dict[str, Any] = spec.get("config", {}) or {}
                StepClass: type[StepProtocol] = STEP_REGISTRY[step_type]
                step_instance: StepProtocol = StepClass(sub_logger, step_config_dict)

                sub_logger.info("Launching substep %d of type '%s'", index, step_type)
                result = step_instance.execute(sub_context)
                if isinstance(result, Awaitable):  # type: ignore
                    await result  # type: ignore
                sub_logger.info("Substep %d completed successfully", index)

            except Exception as exc:
                if failure_exception is None:
                    failure_exception = exc
                    failure_index = index
                sub_logger.error("Substep %d failed: %s", index, exc, exc_info=True)
                # propagate to allow wait to wake
                raise

            finally:
                semaphore.release()

        # Launch substeps with concurrency control and optional delay
        for idx, spec in enumerate(substeps):
            if failure_exception:
                self.logger.debug("Fail-fast: abort launching remaining substeps at index %d", idx)
                break

            await semaphore.acquire()
            if delay_between > 0:
                await asyncio.sleep(delay_between)

            task = asyncio.create_task(run_substep(idx, spec))
            tasks.append(task)

        if not tasks:
            self.logger.info("No substeps launched; nothing to wait for.")
            return

        done: Set[asyncio.Task] = set()
        pending: Set[asyncio.Task] = set()

        # Wait for substeps with first-exception or timeout handling
        try:
            if timeout_seconds is not None:
                done, pending = await asyncio.wait(
                    tasks,
                    timeout=timeout_seconds,
                    return_when=asyncio.FIRST_EXCEPTION,
                )
            else:
                done, pending = await asyncio.wait(
                    tasks,
                    return_when=asyncio.FIRST_EXCEPTION,
                )
        except Exception:
            # Unexpected wait error; consider all tasks done
            done, pending = set(tasks), set()

        # Handle failure
        if failure_exception is not None:
            pending_count = len(pending)
            self.logger.error(
                "Substep %s failed; cancelling %d pending tasks",
                failure_index,
                pending_count,
            )
            for t in pending:
                t.cancel()
            # wait for cancellations
            await asyncio.gather(*pending, return_exceptions=True)
            raise RuntimeError(f"ParallelStep aborted due to failure in substep {failure_index}") from failure_exception

        # Handle timeout without failure
        if pending:
            pending_count = len(pending)
            self.logger.error(
                "ParallelStep timed out after %.3f seconds; cancelling %d pending tasks",
                timeout_seconds,
                pending_count,
            )
            for t in pending:
                t.cancel()
            await asyncio.gather(*pending, return_exceptions=True)
            raise asyncio.TimeoutError(f"ParallelStep timed out after {timeout_seconds} seconds")

        # All successful
        # Gather done to propagate any unexpected exceptions
        await asyncio.gather(*done)
        self.logger.info(
            "Completed ParallelStep: %d/%d substeps succeeded",
            len(done),
            total_steps,
        )
